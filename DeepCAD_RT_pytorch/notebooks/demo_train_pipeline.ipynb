{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DeepCAD-RT training pipeline            \n",
    "<img src=\"https://github.com/STAR-811/DeepCAD-RT-old/blob/main/images/logo-new.png?raw=true\" width = \"650\" height = \"180\" align=right />\n",
    "This file will demonstrate pipeline for training microscopy data using the DeepCAD-RT algorithm.<br>\n",
    "The demo shows how to construct the params and call the relevant functions for training DeepCAD-RT network. In addition, it will automatically download tif file for demo training.<br>\n",
    "\n",
    "More information can be found in the companion paper.\n",
    "See inside for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepcad.train_collection import training_class\n",
    "from deepcad.movie_display import display\n",
    "from deepcad.utils import get_first_filename,download_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select file(s) to be processed (download if not present)\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `datasets` directory. If you adapt this demo for your own data make sure to pass the datasets folder name of your file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_demo_file = False\n",
    "if download_demo_file:\n",
    "    file_name='fish_localbrain' # select the demo file  to be trained (e.g. 'ATP_3D', 'fish_localbrain', 'NP_3D', ...)\n",
    "    datasets_path, _ =download_demo(download_filename=file_name)\n",
    "else:\n",
    "    datasets_path = 'datasets/simulate_-2.51dBSNR_1000frames_demo'  # folder containing files for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up some parameters for training\n",
    "Default setting shows the parameters suitable for demo file. You can change the training parameters accroding to your training data and device. For supervising the training process, you can set the flag for visualization and result storage to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 5               # number of training epochs\n",
    "GPU = '0'                   # the index of GPU you will use for computation (e.g. '0', '0,1', '0,1,2')\n",
    "train_datasets_size = 6000   # datasets size for training (how many patches)\n",
    "patch_xy = 150              # the width and height of 3D patches\n",
    "patch_t = 150               # the time dimension of 3D patches\n",
    "overlap_factor = 0.4        # the overlap factor between two adjacent patches\n",
    "pth_dir = './pth'           # pth file and result visualization path\n",
    "num_workers = 0             # if you use Windows system, set this to 0.\n",
    "\n",
    "# Setup some parameters for result visualization during training period (optional)\n",
    "visualize_images_per_epoch = True  # choose whether to show inference performance after each epoch\n",
    "save_test_images_per_epoch = True  # choose whether to save inference image after each epoch in pth path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Play the demo noisy movie  (optional)\n",
    "Play the first noisy movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDisplaying the first raw file -----> \u001b[0m\n",
      "datasets/simulate_-2.51dBSNR_1000frames_demo/simulate_-2.51dBSNR_1000frames.tif\n"
     ]
    }
   ],
   "source": [
    "display_images = True\n",
    "\n",
    "if display_images:\n",
    "    display_filename = get_first_filename(datasets_path)\n",
    "    print('\\033[1;31mDisplaying the first raw file -----> \\033[0m')\n",
    "    print(display_filename)\n",
    "    display_length = 300  # the frames number of the noise movie\n",
    "    # normalize the image and display\n",
    "    display(display_filename, display_length=display_length, norm_min_percent=1, norm_max_percent=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training class object with the specified parameters\n",
    "You will creat a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTraining parameters -----> \u001b[0m\n",
      "{'overlap_factor': 0.4, 'datasets_path': 'datasets/simulate_-2.51dBSNR_1000frames_demo', 'n_epochs': 5, 'fmap': 16, 'output_dir': './results', 'pth_dir': './pth', 'batch_size': 1, 'patch_t': 150, 'patch_x': 150, 'patch_y': 150, 'gap_y': 90, 'gap_x': 90, 'gap_t': 90, 'lr': 5e-05, 'b1': 0.5, 'b2': 0.999, 'GPU': '0', 'ngpu': 1, 'num_workers': 0, 'scale_factor': 1, 'train_datasets_size': 200, 'select_img_num': 1000000, 'test_datasize': 400, 'visualize_images_per_epoch': True, 'save_test_images_per_epoch': True}\n"
     ]
    }
   ],
   "source": [
    "train_dict = {\n",
    "    # dataset dependent parameters\n",
    "    'patch_x': patch_xy,                # you can change these params if use anisotropy patch size\n",
    "    'patch_y': patch_xy,\n",
    "    'patch_t': patch_t,\n",
    "    'overlap_factor':overlap_factor,\n",
    "    'scale_factor': 1,                   # the factor for image intensity scaling\n",
    "    'select_img_num': 1000000,           # select the number of images used for training (use all frames by default)\n",
    "    'train_datasets_size': train_datasets_size,\n",
    "    'datasets_path': datasets_path,\n",
    "    'pth_dir': pth_dir,\n",
    "    \n",
    "    # network related parameters\n",
    "    'n_epochs': n_epochs,\n",
    "    'lr': 0.00005,                       # initial learning rate\n",
    "    'b1': 0.5,                           # Adam: bata1\n",
    "    'b2': 0.999,                         # Adam: bata2\n",
    "    'fmap': 16,                          # number of feature maps\n",
    "    'GPU': GPU,\n",
    "    'num_workers': num_workers,\n",
    "    'visualize_images_per_epoch': visualize_images_per_epoch,\n",
    "    'save_test_images_per_epoch': save_test_images_per_epoch\n",
    "}\n",
    "\n",
    "tc = training_class(train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mImage list for training -----> \u001b[0m\n",
      "Total stack number ----->  1\n",
      "Noise image name ----->  simulate_-2.51dBSNR_1000frames.tif\n",
      "Noise images shape ----->  (1000, 490, 490)\n",
      "\u001b[1;31mUsing 1 GPU(s) for training -----> \u001b[0m\n",
      "[Epoch 1/5] [Batch 208/208] [Total loss: 133879.38, L1 Loss: 431.95, L2 Loss: 267326.81] [ETA: 0:08:59] [Time cost: 134 s]      \n",
      " Testing model of epoch 1 on the first noisy file ----->\n",
      "Testing image name ----->  simulate_-2.51dBSNR_1000frames.tif\n",
      "Noise images shape ----->  (400, 490, 490)\n",
      " [Patch 100/100] [Time Cost: 15 s] [ETA: 0 s]      \n",
      " Displaying the first denoised file ----->\n",
      "\n",
      "[Epoch 2/5] [Batch 208/208] [Total loss: 146795.33, L1 Loss: 447.59, L2 Loss: 293143.06] [ETA: 0:06:48] [Time cost: 307 s]      \n",
      " Testing model of epoch 2 on the first noisy file ----->\n",
      "Testing image name ----->  simulate_-2.51dBSNR_1000frames.tif\n",
      "Noise images shape ----->  (400, 490, 490)\n",
      " [Patch 100/100] [Time Cost: 14 s] [ETA: 0 s]      \n",
      " Displaying the first denoised file ----->\n",
      "\n",
      "[Epoch 3/5] [Batch 208/208] [Total loss: 166972.73, L1 Loss: 478.81, L2 Loss: 333466.66] [ETA: 0:04:26] [Time cost: 479 s]      \n",
      " Testing model of epoch 3 on the first noisy file ----->\n",
      "Testing image name ----->  simulate_-2.51dBSNR_1000frames.tif\n",
      "Noise images shape ----->  (400, 490, 490)\n",
      " [Patch 100/100] [Time Cost: 15 s] [ETA: 0 s]      \n",
      " Displaying the first denoised file ----->\n",
      "\n",
      "[Epoch 4/5] [Batch 208/208] [Total loss: 139002.17, L1 Loss: 430.49, L2 Loss: 277573.84] [ETA: 0:02:30] [Time cost: 652 s]      \n",
      " Testing model of epoch 4 on the first noisy file ----->\n",
      "Testing image name ----->  simulate_-2.51dBSNR_1000frames.tif\n",
      "Noise images shape ----->  (400, 490, 490)\n",
      " [Patch 100/100] [Time Cost: 15 s] [ETA: 0 s]      \n",
      " Displaying the first denoised file ----->\n",
      "\n",
      "[Epoch 5/5] [Batch 208/208] [Total loss: 166888.28, L1 Loss: 479.46, L2 Loss: 333297.09] [ETA: 0:00:00] [Time cost: 827 s]      \n",
      " Testing model of epoch 5 on the first noisy file ----->\n",
      "Testing image name ----->  simulate_-2.51dBSNR_1000frames.tif\n",
      "Noise images shape ----->  (400, 490, 490)\n",
      " [Patch 100/100] [Time Cost: 15 s] [ETA: 0 s]      \n",
      " Displaying the first denoised file ----->\n",
      "\n",
      " Train finished. Save all models to disk.\n"
     ]
    }
   ],
   "source": [
    "tc.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepcadpip2]",
   "language": "python",
   "name": "conda-env-deepcadpip2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
