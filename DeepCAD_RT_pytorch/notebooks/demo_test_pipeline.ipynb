{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepCAD-RT testing pipeline \n",
    "<img src=\"https://github.com/STAR-811/DeepCAD-RT-old/blob/main/images/logo-new.png?raw=true\" width = \"650\" height = \"180\" align=right />\n",
    "This file will demonstrate pipeline for testing microscopy data using the DeepCAD-RT algorithm.<br>\n",
    "The demo shows how to construct the params and call the relevant functions for testing DeepCAD-RT network. In addition, it will automatically download tif file and corresponding model file for demo testing.<br>\n",
    "\n",
    "More information can be found in the companion paper.\n",
    "See inside for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepcad.test_collection import testing_class\n",
    "from deepcad.movie_display import display\n",
    "from deepcad.utils import get_first_filename, download_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select file(s) to be processed (download if not present)\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `datasets` directory. If you adapt this demo for your data make sure to pass the datasets folder name of your file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://zenodo.org/record/5790790/files/noise_2RPN_-2.51dBSNR_1000frames_.tif?download=1\n",
      "To: E:\\01-LYX\\pipPackage\\DeepCAD_RT_pytorch\\notebooks\\datasets\\simulate_-2.51dBSNR_1000frames_demo\\simulate_-2.51dBSNR_1000frames.tif\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 486M/486M [08:07<00:00, 998kB/s]\n",
      "Downloading...\n",
      "From: https://zenodo.org/record/5790790/files/E_13_Iter_6198.pth?download=1\n",
      "To: E:\\01-LYX\\pipPackage\\DeepCAD_RT_pytorch\\notebooks\\pth\\simulate_-2.51dBSNR_1000frames_best_model_demo\\best_model.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.10M/4.10M [00:02<00:00, 1.56MB/s]\n",
      "Downloading...\n",
      "From: https://zenodo.org/record/5790790/files/para.yaml?download=1\n",
      "To: E:\\01-LYX\\pipPackage\\DeepCAD_RT_pytorch\\notebooks\\pth\\simulate_-2.51dBSNR_1000frames_best_model_demo\\best_model.yaml\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 292/292 [00:00<00:00, 293kB/s]\n"
     ]
    }
   ],
   "source": [
    "download_demo_file = True\n",
    "if download_demo_file:\n",
    "    file_name='simulate_-2.51dBSNR_1000frames' # select the demo file you want to test (e.g. 'ATP_3D', 'fish_localbrain', 'NP_3D', ...)\n",
    "    datasets_path, denoise_model =download_demo(download_filename=file_name)\n",
    "else:\n",
    "    datasets_path = 'datasets/2RPN-1000'  # folder containing files for testing\n",
    "    denoise_model = '2RPN_202112101128_ov_0.5' # A folder containing models to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up some parameters for testing\n",
    "Default setting shows the parameters suitable for demo file. You can change the testing parameters accroding to your testing data and device. For supervising the testing process, you can set the flag for visualization and result storage to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datasize = 300                   # the number of slices to be tested\n",
    "GPU = '0'                             # the index of GPU you will use for computation (e.g. '0', '0,1', '0,1,2')\n",
    "patch_xy = 150              # the width and height of 3D patches\n",
    "patch_t = 150               # the time dimension of 3D patches\n",
    "overlap_factor = 0.4                  # the overlap factor between two adjacent patches\n",
    "num_workers = 0                       # if you use Windows system, set this to 0.\n",
    "\n",
    "# Setup some parameters for result visualization during testing period (optional)\n",
    "visualize_images_per_epoch = False  # choose whether to display inference performance after each epoch\n",
    "save_test_images_per_epoch = True  # choose whether to save inference image after each epoch in pth path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Play the demo noisy movie (optional)\n",
    "Play the first noisy movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDisplaying the first raw file -----> \u001b[0m\n",
      "datasets/simulate_-2.51dBSNR_1000frames_demo/simulate_-2.51dBSNR_1000frames.tif\n"
     ]
    }
   ],
   "source": [
    "display_images = True\n",
    "\n",
    "if display_images:\n",
    "    display_filename = get_first_filename(datasets_path)\n",
    "    print('\\033[1;31mDisplaying the first raw file -----> \\033[0m')\n",
    "    print(display_filename)\n",
    "    display_length = 300  # the frames number of the noise movie\n",
    "    # normalize the image and display\n",
    "    display(display_filename, display_length=display_length, norm_min_percent=1, norm_max_percent=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a testing class object with the specified parameters\n",
    "You will creat a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTesting parameters -----> \u001b[0m\n",
      "{'overlap_factor': 0.5, 'datasets_path': 'datasets/simulate_-2.51dBSNR_1000frames_demo', 'fmap': 16, 'output_dir': './results', 'pth_dir': './pth', 'batch_size': 1, 'patch_t': 150, 'patch_x': 150, 'patch_y': 150, 'gap_y': 75, 'gap_x': 75, 'gap_t': 75, 'GPU': '0', 'ngpu': 1, 'num_workers': 0, 'scale_factor': 1, 'test_datasize': 300, 'denoise_model': 'simulate_-2.51dBSNR_1000frames_best_model_demo', 'visualize_images_per_epoch': False, 'save_test_images_per_epoch': True}\n"
     ]
    }
   ],
   "source": [
    "test_dict = {\n",
    "    # dataset dependent parameters\n",
    "    'patch_x': patch_xy,                # you can change these params if use anisotropy patch size\n",
    "    'patch_y': patch_xy,\n",
    "    'patch_t': patch_t,\n",
    "    'overlap_factor':overlap_factor,\n",
    "    'scale_factor': 1,                   # the factor for image intensity scaling\n",
    "    'test_datasize': test_datasize,\n",
    "    'datasets_path': datasets_path,\n",
    "    'pth_dir': './pth',                 # pth file root path\n",
    "    'denoise_model' : denoise_model,\n",
    "    'output_dir' : './results',         # result file root path\n",
    "    # network related parameters\n",
    "    'fmap': 16,                          # number of feature maps\n",
    "    'GPU': GPU,\n",
    "    'num_workers': num_workers,\n",
    "    'visualize_images_per_epoch': visualize_images_per_epoch,\n",
    "    'save_test_images_per_epoch': save_test_images_per_epoch\n",
    "}\n",
    "\n",
    "tc = testing_class(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mStacks for processing -----> \u001b[0m\n",
      "Total stack number ----->  1\n",
      "simulate_-2.51dBSNR_1000frames.tif\n",
      "\u001b[1;31mUsing 1 GPU(s) for testing -----> \u001b[0m\n",
      "[Model 1/1, best_model.pth] [Stack 1/1, simulate_-2.51dBSNR_1000frames.tif] [Patch 108/108] [Time Cost: 15 s] [ETA: 0 s]      \n",
      " Test finished. Save all results to disk.\n"
     ]
    }
   ],
   "source": [
    "tc.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepcadpip2]",
   "language": "python",
   "name": "conda-env-deepcadpip2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
